# Deep Residual Learning

## Abstaract

- Deep neural network model
    - 152 layers, ensemble
- A residul learning framework
- Higher accuracy

## Figure
    Figure 1. 56-layers network is worse than 20-layers
    Figure 2. Residual learning framework (builing block)
    Figure 3. Example network architectures
    Figure 4. Comparison plain and Resnet acc, val (ImageNet)
    Figure 5. Several residual buliding block by layers depth
    Figure 6. Comparion plain and Resnet train, test acc (CIFAR-10)
    Figure 7. layer response is smaller as layers deeper

## Introduction
- Deep layers occured vanishing/exploding gradients problem.
- Introduce a deep residual learning framework : ( H(x) -> F(x)=H(x)-x), identity shorcut connection.
- Use SGD optimizier.
- Look ImageNet and CIFAR-10 experiments.

## Conclusion
- None

## Summary
